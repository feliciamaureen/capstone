{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from contractions import expandContractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 01 01:11:02 2016\n",
    "@author: DIP\n",
    "author's repo: https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/bonus%20content/nlp%20proven%20approach/contractions.py\n",
    "\"\"\"\n",
    "\n",
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "#remove contractions, code by Dipanjan Sarkar (git linked on contraction map cell)\n",
    "def expandContractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    \n",
    "    return expanded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lyric files\n",
    "eurovision = open(\"data/intersection.txt\", \"r\")\n",
    "c60s = open(\"data/1960s.txt\", \"r\")\n",
    "c70s = open(\"data/1970s.txt\", \"r\")\n",
    "c80s = open(\"data/1980s.txt\", \"r\")\n",
    "c90s = open(\"data/1990s.txt\", \"r\")\n",
    "c00s = open(\"data/2000s.txt\", \"r\")\n",
    "c10s = open(\"data/2010s.txt\", \"r\")\n",
    "\n",
    "eurovisionLyrics = eurovision.read()\n",
    "lyrics60s = c60s.read()\n",
    "lyrics70s = c70s.read()\n",
    "lyrics80s = c80s.read()\n",
    "lyrics90s = c90s.read()\n",
    "lyrics00s = c00s.read()\n",
    "lyrics10s = c10s.read()\n",
    "\n",
    "eurovision.close()\n",
    "c60s.close()\n",
    "c70s.close()\n",
    "c80s.close()\n",
    "c90s.close()\n",
    "c00s.close()\n",
    "c10s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make lowercase\n",
    "def convLower(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "#remove punctuation\n",
    "def removePunctuation(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "#remove non-alphabet characters\n",
    "def removeNonAlphabet(text):\n",
    "    regex = re.sub(r'[^a-zA-Z]', '', text) \n",
    "    return text\n",
    "\n",
    "#remove numbers\n",
    "def removeNumbers(text):\n",
    "    text = \"\".join(i for i in text if not i.isdigit())\n",
    "    return text\n",
    "\n",
    "def cleanText(data):\n",
    "    data = convLower(data)\n",
    "    data = expandContractions(data)\n",
    "    data = removePunctuation(data)\n",
    "    data = removeNonAlphabet(data)\n",
    "    data = removeNumbers(data)\n",
    "    data = removePunctuation(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean lyrics\n",
    "cleanEV = cleanText(eurovisionLyrics)\n",
    "clean60s = cleanText(lyrics60s)\n",
    "clean70s = cleanText(lyrics70s)\n",
    "clean80s = cleanText(lyrics80s)\n",
    "clean90s = cleanText(lyrics90s)\n",
    "clean00s = cleanText(lyrics00s)\n",
    "clean10s = cleanText(lyrics10s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDecades = clean60s + clean70s + clean80s + clean90s + clean00s + clean10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize as words\n",
    "wordsEurovision = word_tokenize(cleanEV)\n",
    "words60s = word_tokenize(clean60s)\n",
    "words70s = word_tokenize(clean70s)\n",
    "words80s = word_tokenize(clean80s)\n",
    "words90s = word_tokenize(clean90s)\n",
    "words00s = word_tokenize(clean00s)\n",
    "words10s = word_tokenize(clean10s)\n",
    "wordsDecades = word_tokenize(cleanDecades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams for each lyrics set\n",
    "bgEV = list(nltk.bigrams(wordsEurovision))\n",
    "bg60s = list(nltk.bigrams(words60s))\n",
    "bg70s = list(nltk.bigrams(words70s))\n",
    "bg80s = list(nltk.bigrams(words80s))\n",
    "bg90s = list(nltk.bigrams(words90s))\n",
    "bg00s = list(nltk.bigrams(words00s))\n",
    "bg10s = list(nltk.bigrams(words10s))\n",
    "bgDecades = list(nltk.bigrams(wordsDecades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique bigrams\n",
    "uniqueBigrams = set(bgEV).union(set(bg60s), set(bg70s), set(bg80s), set(bg90s), set(bg00s), set(bg10s), set(bgDecades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict\n",
    "\n",
    "#returns dictionary of TF values\n",
    "#basic IDF with log\n",
    "def computeIDFBasic(documents):\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict \n",
    "\n",
    "\n",
    "def computeIDFPlusOne(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = 1 + math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "def computeTFIDF(tfData, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfData.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigram count\n",
    "def bigramCount(data):\n",
    "    dictName = dict.fromkeys(uniqueBigrams, 0)\n",
    "    for i in data:\n",
    "        dictName[i] += 1\n",
    "    return dictName\n",
    "\n",
    "bgcEV = bigramCount(bgEV)\n",
    "bgc60s = bigramCount(bg60s)\n",
    "bgc70s = bigramCount(bg70s)\n",
    "bgc80s = bigramCount(bg80s)\n",
    "bgc90s = bigramCount(bg90s)\n",
    "bgc00s = bigramCount(bg00s)\n",
    "bgc10s = bigramCount(bg10s)\n",
    "bgcDecades = bigramCount(bgDecades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF values for bigrams\n",
    "tfbgEV = computeTF(bgcEV, bgEV)\n",
    "tfbg60s = computeTF(bgc60s, bg60s)\n",
    "tfbg70s = computeTF(bgc70s, bg70s)\n",
    "tfbg80s = computeTF(bgc80s, bg80s)\n",
    "tfbg90s = computeTF(bgc90s, bg90s)\n",
    "tfbg10s = computeTF(bgc00s, bg00s)\n",
    "tfbg00s = computeTF(bgc10s, bg10s)\n",
    "tfbgDecades = computeTF(bgcDecades, bgDecades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic IDF value for bigrams\n",
    "bgIDF = computeIDFBasic([bgcEV, bgc60s, bgc70s, bgc80s, bgc90s, bgc00s, bgc10s, bgcDecades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf values\n",
    "tfidfBigramEV = computeTFIDF(tfbgEV, bgIDF)\n",
    "tfidfBigram60s = computeTFIDF(tfbg60s, bgIDF)\n",
    "tfidfBigram70s = computeTFIDF(tfbg70s, bgIDF)\n",
    "tfidfBigram80s = computeTFIDF(tfbg80s, bgIDF)\n",
    "tfidfBigram90s = computeTFIDF(tfbg90s, bgIDF)\n",
    "tfidfBigram00s = computeTFIDF(tfbg00s, bgIDF)\n",
    "tfidfBigram10s = computeTFIDF(tfbg10s, bgIDF)\n",
    "tfidfBigramDecades = computeTFIDF(tfbgDecades, bgIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "biGramData = {'EV': tfidfBigramEV, '60s': tfidfBigram60s, '70s': tfidfBigram70s, '80s': tfidfBigram80s, '90s': tfidfBigram90s, '00s': tfidfBigram00s, '10s': tfidfBigram10s, 'decades': tfidfBigramDecades}\n",
    "dfBigram = pd.DataFrame(data=biGramData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top15Decades = dfBigram.nlargest(15, 'decades')\n",
    "top15EV = dfBigram.nlargest(15, 'decades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigrams for each lyrics set\n",
    "tgEV = list(nltk.trigrams(wordsEurovision))\n",
    "tg60s = list(nltk.trigrams(words60s))\n",
    "tg70s = list(nltk.trigrams(words70s))\n",
    "tg80s = list(nltk.trigrams(words80s))\n",
    "tg90s = list(nltk.trigrams(words90s))\n",
    "tg00s = list(nltk.trigrams(words00s))\n",
    "tg10s = list(nltk.trigrams(words10s))\n",
    "tgDecades = list(nltk.trigrams(wordsDecades))\n",
    "\n",
    "\n",
    "#get unique trigrams\n",
    "uniqueTrigrams = set(tgEV).union(set(tg60s), set(tg70s), set(tg80s), set(tg90s), set(tg00s), set(tg10s), set(tgDecades))\n",
    "\n",
    "#trigram count\n",
    "def trigramCount(data):\n",
    "    dictName = dict.fromkeys(uniqueTrigrams, 0)\n",
    "    for i in data:\n",
    "        dictName[i] += 1\n",
    "    return dictName\n",
    "\n",
    "tgcEV = trigramCount(tgEV)\n",
    "tgc60s = trigramCount(tg60s)\n",
    "tgc70s = trigramCount(tg70s)\n",
    "tgc80s = trigramCount(tg80s)\n",
    "tgc90s = trigramCount(tg90s)\n",
    "tgc00s = trigramCount(tg00s)\n",
    "tgc10s = trigramCount(tg10s)\n",
    "tgcDecades = trigramCount(tgDecades)\n",
    "\n",
    "#TF values for bigrams\n",
    "tftgEV = computeTF(tgcEV, tgEV)\n",
    "tftg60s = computeTF(tgc60s, tg60s)\n",
    "tftg70s = computeTF(tgc70s, tg70s)\n",
    "tftg80s = computeTF(tgc80s, tg80s)\n",
    "tftg90s = computeTF(tgc90s, tg90s)\n",
    "tftg10s = computeTF(tgc00s, tg00s)\n",
    "tftg00s = computeTF(tgc10s, tg10s)\n",
    "tftgDecades = computeTF(tgcDecades, tgDecades)\n",
    "\n",
    "#basic IDF value for bigrams\n",
    "tgIDF = computeIDFBasic([tgcEV, tgc60s, tgc70s, tgc80s, tgc90s, tgc00s, tgc10s, tgcDecades])\n",
    "\n",
    "#tfidf values\n",
    "tfidfTrigramEV = computeTFIDF(tftgEV, tgIDF)\n",
    "tfidfTrigram60s = computeTFIDF(tftg60s, tgIDF)\n",
    "tfidfTrigram70s = computeTFIDF(tftg70s, tgIDF)\n",
    "tfidfTrigram80s = computeTFIDF(tftg80s, tgIDF)\n",
    "tfidfTrigram90s = computeTFIDF(tftg90s, tgIDF)\n",
    "tfidfTrigram00s = computeTFIDF(tftg00s, tgIDF)\n",
    "tfidfTrigram10s = computeTFIDF(tftg10s, tgIDF)\n",
    "tfidfTrigramDecades = computeTFIDF(tftgDecades, tgIDF)\n",
    "\n",
    "#summarise results in dataframe\n",
    "triGramData = {'EV': tfidfTrigramEV, '60s': tfidfTrigram60s, '70s': tfidfTrigram70s, '80s': tfidfTrigram80s, '90s': tfidfTrigram90s, '00s': tfidfTrigram00s, '10s': tfidfTrigram10s, 'decades': tfidfTrigramDecades}\n",
    "dfTrigram = pd.DataFrame(data=triGramData)\n",
    "\n",
    "#top 15 values sorted by Eurovision and Decades\n",
    "top15EV = dfTrigram.nlargest(15, 'EV')\n",
    "top15Decades = dfTrigram.nlargest(15, 'decades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>EV</th>\n",
       "      <th>60s</th>\n",
       "      <th>70s</th>\n",
       "      <th>80s</th>\n",
       "      <th>90s</th>\n",
       "      <th>00s</th>\n",
       "      <th>10s</th>\n",
       "      <th>decades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <th>’</th>\n",
       "      <th>t</th>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <th>thank</th>\n",
       "      <th>you</th>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <th>you</th>\n",
       "      <th>thank</th>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <th>got</th>\n",
       "      <th>love</th>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heaven</th>\n",
       "      <th>and</th>\n",
       "      <th>earth</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>might</th>\n",
       "      <th>now</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <th>your</th>\n",
       "      <th>toy</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shine</th>\n",
       "      <th>a</th>\n",
       "      <th>light</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <th>the</th>\n",
       "      <th>voice</th>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rock</th>\n",
       "      <th>me</th>\n",
       "      <th>baby</th>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <th>s</th>\n",
       "      <th>no</th>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irlande</th>\n",
       "      <th>douze</th>\n",
       "      <th>points</th>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <th>vote</th>\n",
       "      <th>vote</th>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let</th>\n",
       "      <th>’</th>\n",
       "      <th>s</th>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <th>cold</th>\n",
       "      <th>cold</th>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            EV  60s  70s  80s       90s       00s       10s  \\\n",
       "don     ’     t       0.000878  0.0  0.0  0.0  0.000061  0.000042  0.000229   \n",
       "you     thank you     0.000836  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "thank   you   thank   0.000717  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "we      got   love    0.000717  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "heaven  and   earth   0.000657  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "i       might now     0.000657  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "not     your  toy     0.000657  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "shine   a     light   0.000657  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "am      the   voice   0.000597  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "rock    me    baby    0.000538  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "’       s     no      0.000535  0.0  0.0  0.0  0.000000  0.000000  0.000026   \n",
       "irlande douze points  0.000478  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "vote    vote  vote    0.000478  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "let     ’     s       0.000438  0.0  0.0  0.0  0.000000  0.000015  0.000073   \n",
       "cold    cold  cold    0.000418  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "                       decades  \n",
       "don     ’     t       0.000051  \n",
       "you     thank you     0.000000  \n",
       "thank   you   thank   0.000000  \n",
       "we      got   love    0.000000  \n",
       "heaven  and   earth   0.000000  \n",
       "i       might now     0.000000  \n",
       "not     your  toy     0.000000  \n",
       "shine   a     light   0.000000  \n",
       "am      the   voice   0.000000  \n",
       "rock    me    baby    0.000000  \n",
       "’       s     no      0.000005  \n",
       "irlande douze points  0.000000  \n",
       "vote    vote  vote    0.000000  \n",
       "let     ’     s       0.000015  \n",
       "cold    cold  cold    0.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top15Decades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>EV</th>\n",
       "      <th>60s</th>\n",
       "      <th>70s</th>\n",
       "      <th>80s</th>\n",
       "      <th>90s</th>\n",
       "      <th>00s</th>\n",
       "      <th>10s</th>\n",
       "      <th>decades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lie</th>\n",
       "      <th>la</th>\n",
       "      <th>lie</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovely</th>\n",
       "      <th>day</th>\n",
       "      <th>lovely</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>lovely</th>\n",
       "      <th>day</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>na</th>\n",
       "      <th>na</th>\n",
       "      <th>na</th>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <th>lie</th>\n",
       "      <th>la</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>species</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <th>post</th>\n",
       "      <th>office</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lo</th>\n",
       "      <th>lo</th>\n",
       "      <th>lo</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>fire</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <th>gone</th>\n",
       "      <th>with</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <th>head</th>\n",
       "      <th>be</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gone</th>\n",
       "      <th>with</th>\n",
       "      <th>it</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head</th>\n",
       "      <th>be</th>\n",
       "      <th>gone</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever</th>\n",
       "      <th>do</th>\n",
       "      <th>you</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <th>ever</th>\n",
       "      <th>do</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             EV       60s       70s       80s       90s  00s  \\\n",
       "lie    la     lie      0.000000  0.000000  0.005054  0.000000  0.000000  0.0   \n",
       "lovely day    lovely   0.000000  0.000000  0.004799  0.000000  0.000000  0.0   \n",
       "day    lovely day      0.000000  0.000000  0.004748  0.000000  0.000000  0.0   \n",
       "na     na     na       0.000099  0.000003  0.000000  0.000596  0.001996  0.0   \n",
       "la     lie    la       0.000000  0.000000  0.003369  0.000000  0.000000  0.0   \n",
       "of     the    species  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "the    post   office   0.000000  0.000432  0.000000  0.000000  0.000000  0.0   \n",
       "lo     lo     lo       0.000000  0.000000  0.002655  0.000000  0.000000  0.0   \n",
       "by     the    fire     0.000000  0.000377  0.000000  0.000000  0.000000  0.0   \n",
       "be     gone   with     0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "go     head   be       0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "gone   with   it       0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "head   be     gone     0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "ever   do     you      0.000000  0.000000  0.000000  0.000951  0.000000  0.0   \n",
       "how    ever   do       0.000000  0.000000  0.000000  0.000951  0.000000  0.0   \n",
       "\n",
       "                            10s   decades  \n",
       "lie    la     lie      0.000000  0.000321  \n",
       "lovely day    lovely   0.000000  0.000305  \n",
       "day    lovely day      0.000000  0.000302  \n",
       "na     na     na       0.000042  0.000277  \n",
       "la     lie    la       0.000000  0.000214  \n",
       "of     the    species  0.001098  0.000195  \n",
       "the    post   office   0.000000  0.000178  \n",
       "lo     lo     lo       0.000000  0.000169  \n",
       "by     the    fire     0.000000  0.000156  \n",
       "be     gone   with     0.000823  0.000146  \n",
       "go     head   be       0.000823  0.000146  \n",
       "gone   with   it       0.000823  0.000146  \n",
       "head   be     gone     0.000823  0.000146  \n",
       "ever   do     you      0.000000  0.000143  \n",
       "how    ever   do       0.000000  0.000143  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top15EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "triGramCount = {'EV': tgcEV, '60s': tgc60s, '70s': tgc70s, '80s': tgc80s, '90s': tgc90s, '00s': tgc00s, '10s': tgc10s, 'decades': tgcDecades}\n",
    "dfTrigramCount = pd.DataFrame(data=triGramCount)\n",
    "\n",
    "biGramCount = {'EV': bgcEV, '60s': bgc60s, '70s': bgc70s, '80s': bgc80s, '90s': bgc90s, '00s': bgc00s, '10s': bgc10s, 'decades': bgcDecades}\n",
    "dfBigramCount = pd.DataFrame(data=biGramCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>EV</th>\n",
       "      <th>60s</th>\n",
       "      <th>70s</th>\n",
       "      <th>80s</th>\n",
       "      <th>90s</th>\n",
       "      <th>00s</th>\n",
       "      <th>10s</th>\n",
       "      <th>decades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lie</th>\n",
       "      <th>la</th>\n",
       "      <th>lie</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovely</th>\n",
       "      <th>day</th>\n",
       "      <th>lovely</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>lovely</th>\n",
       "      <th>day</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>na</th>\n",
       "      <th>na</th>\n",
       "      <th>na</th>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <th>lie</th>\n",
       "      <th>la</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>species</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <th>post</th>\n",
       "      <th>office</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lo</th>\n",
       "      <th>lo</th>\n",
       "      <th>lo</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>fire</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <th>gone</th>\n",
       "      <th>with</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <th>head</th>\n",
       "      <th>be</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gone</th>\n",
       "      <th>with</th>\n",
       "      <th>it</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head</th>\n",
       "      <th>be</th>\n",
       "      <th>gone</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever</th>\n",
       "      <th>do</th>\n",
       "      <th>you</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <th>ever</th>\n",
       "      <th>do</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             EV       60s       70s       80s       90s  00s  \\\n",
       "lie    la     lie      0.000000  0.000000  0.005054  0.000000  0.000000  0.0   \n",
       "lovely day    lovely   0.000000  0.000000  0.004799  0.000000  0.000000  0.0   \n",
       "day    lovely day      0.000000  0.000000  0.004748  0.000000  0.000000  0.0   \n",
       "na     na     na       0.000099  0.000003  0.000000  0.000596  0.001996  0.0   \n",
       "la     lie    la       0.000000  0.000000  0.003369  0.000000  0.000000  0.0   \n",
       "of     the    species  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "the    post   office   0.000000  0.000432  0.000000  0.000000  0.000000  0.0   \n",
       "lo     lo     lo       0.000000  0.000000  0.002655  0.000000  0.000000  0.0   \n",
       "by     the    fire     0.000000  0.000377  0.000000  0.000000  0.000000  0.0   \n",
       "be     gone   with     0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "go     head   be       0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "gone   with   it       0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "head   be     gone     0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "ever   do     you      0.000000  0.000000  0.000000  0.000951  0.000000  0.0   \n",
       "how    ever   do       0.000000  0.000000  0.000000  0.000951  0.000000  0.0   \n",
       "\n",
       "                            10s   decades  \n",
       "lie    la     lie      0.000000  0.000321  \n",
       "lovely day    lovely   0.000000  0.000305  \n",
       "day    lovely day      0.000000  0.000302  \n",
       "na     na     na       0.000042  0.000277  \n",
       "la     lie    la       0.000000  0.000214  \n",
       "of     the    species  0.001098  0.000195  \n",
       "the    post   office   0.000000  0.000178  \n",
       "lo     lo     lo       0.000000  0.000169  \n",
       "by     the    fire     0.000000  0.000156  \n",
       "be     gone   with     0.000823  0.000146  \n",
       "go     head   be       0.000823  0.000146  \n",
       "gone   with   it       0.000823  0.000146  \n",
       "head   be     gone     0.000823  0.000146  \n",
       "ever   do     you      0.000000  0.000143  \n",
       "how    ever   do       0.000000  0.000143  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrigram.nlargest(15, 'decades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>EV</th>\n",
       "      <th>60s</th>\n",
       "      <th>70s</th>\n",
       "      <th>80s</th>\n",
       "      <th>90s</th>\n",
       "      <th>00s</th>\n",
       "      <th>10s</th>\n",
       "      <th>decades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mam</th>\n",
       "      <th>says</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <th>lie</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lie</th>\n",
       "      <th>la</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>na</th>\n",
       "      <th>na</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>lovely</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>malachy</th>\n",
       "      <th>and</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <th>lane</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea</th>\n",
       "      <th>and</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uncle</th>\n",
       "      <th>pa</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aunt</th>\n",
       "      <th>aggie</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lo</th>\n",
       "      <th>lo</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovely</th>\n",
       "      <th>day</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dad</th>\n",
       "      <th>says</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">and</th>\n",
       "      <th>mam</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tells</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      EV       60s       70s       80s       90s  00s  \\\n",
       "mam     says    0.000000  0.001185  0.000000  0.000000  0.000000  0.0   \n",
       "la      lie     0.000000  0.000000  0.005615  0.000000  0.000000  0.0   \n",
       "lie     la      0.000000  0.000000  0.005615  0.000000  0.000000  0.0   \n",
       "na      na      0.000124  0.000005  0.000000  0.000619  0.002349  0.0   \n",
       "day     lovely  0.000000  0.000000  0.004798  0.000000  0.000000  0.0   \n",
       "malachy and     0.000000  0.000659  0.000000  0.000000  0.000000  0.0   \n",
       "the     lane    0.000000  0.000659  0.000000  0.000000  0.000000  0.0   \n",
       "tea     and     0.000000  0.000604  0.000000  0.000000  0.000000  0.0   \n",
       "uncle   pa      0.000000  0.000596  0.000000  0.000000  0.000000  0.0   \n",
       "aunt    aggie   0.000000  0.000588  0.000000  0.000000  0.000000  0.0   \n",
       "lo      lo      0.000000  0.000000  0.003829  0.000000  0.000000  0.0   \n",
       "lovely  day     0.000000  0.000006  0.003720  0.000000  0.000000  0.0   \n",
       "dad     says    0.000000  0.000565  0.000000  0.000000  0.000000  0.0   \n",
       "and     mam     0.000000  0.000541  0.000000  0.000000  0.000000  0.0   \n",
       "        tells   0.000000  0.000518  0.000000  0.000000  0.000000  0.0   \n",
       "\n",
       "                     10s   decades  \n",
       "mam     says    0.000000  0.000490  \n",
       "la      lie     0.000000  0.000357  \n",
       "lie     la      0.000000  0.000357  \n",
       "na      na      0.000046  0.000314  \n",
       "day     lovely  0.000000  0.000305  \n",
       "malachy and     0.000000  0.000273  \n",
       "the     lane    0.000000  0.000273  \n",
       "tea     and     0.000000  0.000250  \n",
       "uncle   pa      0.000000  0.000247  \n",
       "aunt    aggie   0.000000  0.000243  \n",
       "lo      lo      0.000000  0.000243  \n",
       "lovely  day     0.000000  0.000239  \n",
       "dad     says    0.000000  0.000234  \n",
       "and     mam     0.000000  0.000224  \n",
       "        tells   0.000000  0.000214  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBigram.nlargest(15, 'decades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
